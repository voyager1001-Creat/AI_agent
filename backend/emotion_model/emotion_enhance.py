from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
import os
from pathlib import Path

# æ·»åŠ è¨­å‚™è¨­å®š
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# æ¨™ç±¤æ˜ å°„å­—å…¸
label_mapping = {
    0: "å¹³æ·¡",
    1: "å…³åˆ‡",
    2: "å¼€å¿ƒ",
    3: "æ„¤æ€’",
    4: "æ‚²ä¼¤",
    5: "ç–‘é—®",
    6: "æƒŠè®¶",
    7: "åŒæ¶"
}

def predict_emotion(text, model_path=None):
    """
    é¢„æµ‹æ–‡æœ¬æƒ…æ„Ÿ
    
    Args:
        text: è¾“å…¥æ–‡æœ¬
        model_path: æ¨¡å‹è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤è·¯å¾„
    
    Returns:
        é¢„æµ‹çš„æƒ…æ„Ÿæ ‡ç­¾
    """
    if model_path is None:
        # è·å–å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•
        current_dir = Path(__file__).parent
        model_path = current_dir / "Chinese-Emotion-Small"
        model_path = str(model_path)
    
    print(f"ğŸ” ä½¿ç”¨æ¨¡å‹è·¯å¾„: {model_path}")
    
    # æ£€æŸ¥æ¨¡å‹è·¯å¾„æ˜¯å¦å­˜åœ¨
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {model_path}")
    
    try:
        # è¼‰å…¥æ¨¡å‹å’Œåˆ†è©å™¨
        print(" åŠ è½½åˆ†è¯å™¨...")
        tokenizer = AutoTokenizer.from_pretrained(model_path, local_files_only=True)
        
        print(" åŠ è½½æ¨¡å‹...")
        model = AutoModelForSequenceClassification.from_pretrained(
            model_path, 
            local_files_only=True
        ).to(device)
        
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
        
        # å°‡æ–‡æœ¬è½‰æ›ç‚ºæ¨¡å‹è¼¸å…¥æ ¼å¼
        inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True).to(device)
        
        # é€²è¡Œé æ¸¬
        with torch.no_grad():
            outputs = model(**inputs)
        
        # å–å¾—é æ¸¬çµæœ
        predicted_class = torch.argmax(outputs.logits).item()
        predicted_emotion = label_mapping[predicted_class]
        
        return predicted_emotion
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        raise e

if __name__ == "__main__":
    # ä½¿ç”¨ç¯„ä¾‹
    test_texts = [
        "é›–ç„¶æˆ‘åŠªåŠ›äº†å¾ˆä¹…ï¼Œä½†ä¼¼ä¹ç¸½æ˜¯åšä¸åˆ°ï¼Œæˆ‘æ„Ÿåˆ°è‡ªå·±ä¸€ç„¡æ˜¯è™•ã€‚",
        "ä½ èªªçš„é‚£äº›è©±çœŸçš„è®“æˆ‘å¾ˆå›°æƒ‘ï¼Œå®Œå…¨ä¸çŸ¥é“è©²æ€éº¼åæ‡‰ã€‚",
        "é€™ä¸–ç•ŒçœŸçš„æ˜¯ç„¡æƒ…ï¼Œç‚ºä»€éº¼æ¯æ¬¡éƒ½è¦çµ¦æˆ‘é€™æ¨£çš„è€ƒé©—ï¼Ÿ",
        "æœ‰æ™‚å€™ï¼Œæˆ‘åªå¸Œæœ›èƒ½æœ‰ä¸€é»å®‰éœï¼Œä¸è¦å†è½åˆ°é€™äº›ç„¡èŠçš„è©±é¡Œã€‚",
        "æ¯æ¬¡æƒ³èµ·é‚£æ®µéå»ï¼Œæˆ‘çš„å¿ƒé‚„æ˜¯æœƒç—›ï¼ŒçœŸçš„ç„¡æ³•é‡‹æ‡·ã€‚",
        "æˆ‘å¾ä¾†æ²’æœ‰æƒ³éæœƒæœ‰é€™éº¼å¤§çš„æ”¹è®Šï¼Œç¾åœ¨æˆ‘è¦ºå¾—è‡ªå·±å®Œå…¨å¤±æ§äº†ã€‚",
        "æˆ‘å®Œå…¨æ²’æƒ³åˆ°ä½ æœƒé€™éº¼åšï¼Œé€™è®“æˆ‘é©šè¨åˆ°ç„¡æ³•è¨€å–»ã€‚",
        "æˆ‘çŸ¥é“æˆ‘æ‡‰è©²æ›´å …å¼·ï¼Œä½†æœ‰äº›æ™‚å€™ï¼Œé€™ç¨®æƒ…ç·’çœŸçš„è®“æˆ‘å¿«è¦å´©æ½°äº†ã€‚"
    ]

    for text in test_texts:
        try:
            emotion = predict_emotion(text)
            print(f"æ–‡æœ¬: {text}")
            print(f"é æ¸¬æƒ…ç·’: {emotion}\n")
        except Exception as e:
            print(f"âŒ é¢„æµ‹å¤±è´¥: {e}\n")